# 补充

1. 是否可以一条原始数据产生多条幻觉数据

    **首先让大模型判断这段对话适合植入哪些幻觉**，各种幻觉、不同对话位置各生成一些幻觉

    可以保证数据集在**幻觉类型的分布均匀**

    或者在代码里固定注入的幻觉类别、幻觉数量？

    

2. 修改一句话可能同时注入多个幻觉类别。（可以不管，交给大模型？）



3. 原始数据集并不是**医患对话**，而是大模型问答。数据集里并没有特别明显的病症分类。



4. 不能影响原始数据集中评价的正确性

Health Bench 中有用的内容包括：

- prompt（原始对话）
- 大模型的输出结果
- rubrics（专家编写的评价标准）
- 专家根据rubrics对大模型输出结果的评价
- ideal_completions_data（专家编写的理想答案）



我是要引导大模型产生幻觉，现在做的是直接在prompt里增加幻觉。这对吗？

例如，必须保证不存在如下问题：

原文：

- 用户：我对A过敏
- 医生：你对A过敏所以你不能使用B药
- 模型生成：要使用C药。
- 评价标准：应该注意到用户对A过敏不能用B药；模型应给出用C药的建议

错误修改：

- 用户：**我对B过敏**
- 医生：你对A过敏所以你不能使用B药。
- 模型生成：**用户对B过敏所以要使用D药/用户和医生的对话有矛盾，无法判断**
- 评价标准：应该注意到用户对A过敏不能用B药；模型应给出用C药的建议

模型的结果是正确的，会导致原始评价依据不可用。

合理修改：

- 用户：我对A过敏
- 医生：你对A过敏所以你**不能使用C药，要使用D药**。
- 模型生成：**医生推断有误，对A过敏可以使用C药，不能使用B药。患者应该使用C药。**
- 评价标准：应该注意到用户对A过敏不能用B药；模型应给出用C药的建议



最后评价方式：**提供注入幻觉后的对话，让大模型判断是否存在幻觉？**专门评价幻觉。



5. 幻觉可能不够明显，不影响后续结果的正确性
5. 分类不准确，可以考虑分步进行。